Виконання полягає у письмовій відповіді на 2 запитання. 
Також слід обов'язково вказати: № групи, П.І.П. та переписати запитання.
Номер першого запитання = номер прізвища студента в списку групи.
Номер друго запитання = номер прізвища студента в списку групи + 2. 
ПДФ-файл слід викласти в класрум. 
Контрольна робота No1 включає такі запитання:
1. Поняття нейронної мережі.
2. Архітектура нейромережевих засобів розпізнавання.
3. Поняття штучного нейрону.
4. Методи навчання нейронної мережі.
5. Поняття навчальної вибірки.
6. Поняття та види функцій активації.
7. Тренувальна, тестова та валідаційна вибірка.
8. Архітектура двошарового персептрону.
9. Переваги та недоліки двошарового персептрону.
10. Класифікація нейронних мереж.
11. Переваги та недоліки нейромережевих засобів розпізнавання.
12. Передумови та принципи створення згорткової нейронної мережі.
13. Поняття згортки та субдискретизації.
14. Типова структура згорткової нейронної мережі.
15. Перелік конструктивних параметрів згорткової нейронної мережі.
16. Функції активації в шарах згортки та в повнозв’язних шарах.
17. Характеристика згорткової нейронної мережі типу LeNet.
18. Порівняння згорткових нейронних мереж та мереж з прямим розповсюдженням сигналу.
19. Деталізація процедур згортки та субдискретизації.
20. Розрахунок структурних параметрів згорткової нейронної мережі.
21. Особливості розпізнавання багатоканальних кольорових зображень за допомогою згорткової
нейронної мережі.
22. Характеристика згорткової нейронної мережі ResNet.
23. Характеристика згорткової нейронної мережі AlexNet.
24. Характеристика згорткової нейронної мережі VGG.
25. Характеристика згорткової нейронної мережі GoogLeNet.
26. Характеристика згорткової нейронної мережі SqueezeNet.
27. Оцінка ефективності різних типів згорткових нейронних мереж.
28. Концепція ієрархічного розпізнавання.
29. Критерії оцінки обчислювальної потужності нейромережевої моделі.
30. Архітектура багатошарового персептрону.
31. Переваги та недоліки багатошарового персептрону.
32. Обмеження багатошарового персептрону з сигмоїдальною функцією активації.
33. Підходи до подолання ефекту «затухання градієнту». Функція активації ReLU.
34. Недоліки застосування ReLU та шляхи виправлення. Процедура Dropout.
35. Обмеження щодо застосування нейронних мереж з прямим розповсюдженням сигналу.
36. Підходи до обробки зареєстрованих даних.
37. Оцінка можливості формування маркованих та немаркованих навчальних прикладів,
кількість яких достатня для ефективного навчання нейромережевої моделі.
38. Нормалізація вхідних та вихідних параметрів.